% glossary.tex - thesis example with glossary
\documentclass[12pt,glossary]{dalthesis}
% to prepare draft version use option draft:
%\documentclass[12pt,draft]{dalthesis}


\usepackage{amssymb}
\usepackage{blindtext}
\usepackage{enumitem}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsthm}
\usepackage{graphicx} %package to manage images1v
\graphicspath{ {Figures/} }
\usepackage[linesnumbered,ruled]{algorithm2e}
\usepackage{multirow}
\usepackage{setspace}
\usepackage{url}
\renewcommand{\baselinestretch}{2.0}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}


\begin{document}

\macs  % options are \mcs, \macs, \mec, \mhi, \phd, and \bcshon
\title{COMPACT REPRESENTATION OF SEPARABLE GRAPH}``
\author{Xiang Zhang}
\defenceday{1}
\defencemonth{August}
\defenceyear{2017}
\convocation{September}{2017}

% Use multiple \supervisor commands for co-supervisors.
% Use one \reader command for each reader.

\supervisor{Dr. Meng He}
\reader{D. Odaprof}
\reader{A. External}



\frontmatter





\begin{abstract}
Nowadays, the problem of designing space-efficient data structures to represent graphs while supporting efficient queries operations has drawn a great deal of attention. Plenty of previous works have been conducted to represent graphs "succinctly", which means representing the graphs in a compact representation whose space cost is close to the information-theoretic lower bound, and still supports efficient query operations. An available approach is making use of small separator of a separable graph to represent the graph compactly. The representation used $O(n)$ bits, meanwhile using constant time on thee degree or adjacency queries as well as neighbour listing in constant time per neighbour.

We implement this data structure by using edge separator. The data structure is building by recursively partitioning a graph into two subgraphs until only one vertex left. We store an adjacency list for each vertex, then concatenate the adjacency lists in the order of renumbered vertex to form an adjacency table. Then we implement several indexing structures to support adjacency queries, degree queries and neighbourhood queries in constant time. We conduct some experience to measure the performance of our representation. The experiment shows our approach reduces space usage by almost an order of magnitude, while supporting Breadth-first-search in acceptable running time when compared to the array-based adjacency list representation.
\end{abstract}

\printglossary

\begin{acknowledgements}
My Supervisor, Dr. Meng He, deserves the most praise for his invaluable guidance, friendship and suggestions. I would also like to thank all of the friends and acquaintances I have made at Dalhousie University. They have made this journey something to remember. Without everyoneâ€™s support and guidance this project would have not been a success.
I would like to thank Dalhousie University to provide such a great environment
to do research and allowing me to finish my work.
I am proudly grateful to my supportive and loving family for their whole-hearted
support of my graduate studies.
\end{acknowledgements}

\mainmatter

\chapter{Introduction}

Nowadays, many applications use graphs to show the relationship and represent connectivity between multiple objects. The usage of such graphs is so popular in representing various of data types including link structure of the web, 3d models in mesh, geographic maps, and surface meshes in computer graphics, etc. As the graphs inevitably grow very huge, the space issue becomes ever more important. Hence, the problem of designing space-efficient data structures to represent graphs while supporting efficient queries operations has drawn a great deal of attention. 

\bigskip
Plenty of previous works have been conducted to represent graphs "succinctly", which means representing the graphs in a compact representation whose space cost is close to the information-theoretic lower bound, and still supports efficient query operations. The problem of succinctly representation of a graph can be formalized as: Given a graph $G = (V, E)$ of type $\chi$, where n and m are numbers of vertexes and edges, respectively, then represent $G$ using $\lg | \chi | + o(\lg | \chi | )$ bits of space, and support a set of query operations on the graph in constant time ( assuming we can access $\Theta(\lg n)$ consecutive bits in one operation ). Because the space bound may not be satisfied, therefore, the trade-off between space cost and query time can be further investigated.  

\bigskip

A considerable strategy to save the space when represent graphs is taking advantage of structural properties of graphs. In practice, the most common structural property of graphs is they have small separators. A graph has separators if it can be partitioned into two subgraphs in approximately equal size by removing a few vertexes. For example, Planar graphs, have $O(n^{1/2})$ separators, and even graphs that are not strictly planar because of crossings, such power networks, have small separators too. More generally, nearly all graphs that represent connections relationship in low dimensional spaces have small separators. We say a graph is separable if it is taken from a class of graphs that satisfies an $n^{c}$-separator theorem~\cite{separator-theorem} for some constant c $<$ 1.

\bigskip

In this project, we are interested in improving a compact representation mechanism for separable graphs presented by a previous work ~\cite{compact-representation}. In which work the authors proposed an approach to representing separable graphs compactly. Their representation used $O(n)$ bits, meanwhile using constant time on degree or adjacency query, and neighbour listing for one vertex in constant time per neighbour (They took advantage of $O(\lg n)$-bit parallelism computation to access $\Theta(\lg n)$ consecutive bits in one operation). Graphs with good separators got good compression by using their representation, and even graphs that are not strictly separable, their representation still works well because the separable components in those graphs can be compressed.In their paper, they provided detail description for compressing the graph by building two structures: the adjacency table and the root-find structure ~\cite{compact-representation}, which used vertex separators to encode the graph into a shadow adjacency table ~\cite{compact-representation}, as well as support constant time on query operations. But their experiment implemented the data structure by using edge separator instead of vertex separator, which means the shadow label and root-find structure were not needed. In this project, we implement the data structure by using edge separator, and conduct experiments on it.

\bigskip
\bigskip

We firstly followed their idea to implement the data structure by using edge separator. The data structure was built by recursively partitioning a graph into two subgraphs until only one vertex left. During the partition process, an edge separator tree was built. Then we made use of the edge separator tree to renumber the vertexes. We stored an adjacency list for each vertex, then concatenated the adjacency lists in the order of renumbered vertex to form an adjacency table. Each pair of vertexes in the adjacency was stored by encoding the difference $d$ between the two vertexes, and all the differences are stored contiguously as a sequence of bits in memory. We show, by using adjacency table, $O(n)$ bits are sufficient to encode the separable graph. 

\bigskip
\bigskip

Next, we implemented several index structures to support degree and adjacency query in constant time, and neighbour listing in constant time per Neighbour. The index structures contain all the index structures involved in their experiment, as well as two index structures implemented by us which apply succinct data structures on bit vector. In their paper, they encoded the degree of each vertex at the start of each adjacency list. However, the space of degree can be saved in some cases, which causes a trade-off between the time to support degree queries and the space to encode the graph.

\bigskip
\bigskip

Finally, We compared the performance of various indexing structure by conduct a breadth-first-search on the graph represented by different indexing structure. We also compared our space and time cost to that of an array-based adjacency list representation. The result showed that our implementation save a magnitude of space when compared to standard array-based adjacency list, while supported efficient queries.   

\section{Related Works}

There have been considerable works dedicate to compress graphs such as planar graphs, k-Page graphs and separable graphs. The first attempt of succinct representation of graphs was conducted by Jacobson~\cite{Jacobson}, who first showed how to represent planar graph by using O(n) bits while supporting adjacency queries in $O(\log n)$ time. His approach decomposes a planar graph into at most four one-page graphs which are represented as a sequence of balanced parentheses. His representation extended naturally to a $k$-page graph problem, where k$\geq$1.

\bigskip
\bigskip

Munro and Raman~\cite{Munro} improved the time for adjacency queries to O(1) time while using $8n+2m$ bits where $n$ and $m$ are numbers of vertexes and edges respectively. Their work gives a great reduction in the higher order term for a number of bits regarding Jacobson's parenthesis representation, and further expands the types of operations on parenthesis representation. Geary $et$ $al.$~\cite{Geary} gave a conceptually simpler representation compared to Jacobson's data structure, they used $2n+o(n)$ bits while supporting natural parenthesis operations in $O(1)$ time. The space constants on the high order term has been improved by Chuang $et$ $al.$~\cite{Chuang}, and further by Chiang $et$ $al.$~\cite{Chiang}. The former proposed another encoding mechanism based on $canonical orderings$ of a planar graph, then used a $multiple parentheses sequences$ to represent the graph, while the latter generalized the notion of canonical orderings to orderly spanning trees and improved constant factors in terms of numbers of vertexes and edges. 

\bigskip
\bigskip

A succinct representation for a k-page graph when k is large to support various navigational
operations more efficiently, was proposed by Barbay $et$ $al.$~\cite{Barbay}, whose representation used $n+2m\lg n + m \cdot o(\lg k) + o(m)$ bits to support adjacency queries in $O(\lg k \lg \lg k)$ time, degree queries in constant time and neighbourhood in $O(d(x) \lg \lg k)$, where $d(x)$ is the degree of vertex $x$, or used $n+(2+\epsilon)m\lg k + m \cdot o(\lg k) + O(m)$ bits to support adjacency, degree and neighbourhood queries in $O(\lg k)$, $O(1)$ and $O(d(x))$ time, respectively, where $\epsilon$ is any constant satisfies $0< \epsilon <1$.   

\bigskip

\begin{table}[ht]
\centering
\caption{A summary of performance of various of succinct planar graph representations. Notation: "Pla*" indicates the planar graphs, "k-p*" indicates the k-page graphs, "Tri*" indicates the triangulation graphs, "Sep*" indicates the separable graphs, $n$ and $m$ denote the numbers of vertexes and edges in Graph $G$, respectively, $i$ is the number of isolated vertexes in $G$, $\epsilon$ is an arbitrary positive constant, $\tau$ = min\{ $\lg k / \lg \lg m, \lg \lg k$, and $H$ is the information theoretic lower bound regarding storing a separable graph. \}  Triangulation}
\label{my-label}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Type                       & Ref. & Space & Adjacency & Neighborhood & Degree \\ \hline
\multirow{4}{*}{Pla*}    &  ~\cite{Jacobson}    & $O(n)$ &   $O(\lg n)$   &       $O(deg(x) \lg n)$       &    $0(\lg n)$    \\ \cline{2-6} 
                           &   ~\cite{Chuang} &  $\frac{3}{5} m + (5+ \epsilon )n + o(n) $  & $O(1)$  & $O(deg(x))$ &   $O(1)$     \\ \cline{2-6} 
                           & ~\cite{Chiang} & $2m+2n+0(m+n)$& $O(1)$  &  $O(deg(x))$  &  $O(1)$     \\ \cline{2-6} 
                           & ~\cite{Munro} & $2m+8n+o(n)$&  $O(1)$  &  $O(deg(x))$  &   $O(1)$  \\ \hline
\multirow{5}{*}{k-p*}    &  ~\cite{Jacobson} &  $O(kn)$  & $O(\lg n + k)$  &  $O(geg(x)\lg n$  &  $O(\lg n)$ \\ \cline{2-6} 
                           &   ~\cite{Gavoille}   & $(2(m+i)+o(m+i))\lg k$ & $O(\tau \lg k)$  &  $O(deg(x) \tau)$ & O(1) \\ \cline{2-6} 
                           &  ~\cite{Barbay} & $2m \lg k+n+o(m \lg k)$  & $O(\lg k \lg \lg k)$  & $O(deg(x) \lg \lg k)$ &   $O(1)$  \\ \cline{2-6} 
                           &   ~\cite{Barbay}   & $(2+\epsilon )m\lg k+n+o(m\lg k)$ & $O(\lg k)$ & $O(deg(x))$& $O(1)$        \\ \cline{2-6} 
                           &~\cite{Munro} & $2m+2kn+o(kn)$ & $O(k)$  & $O(deg(x)+k)$ &  $O(1)$  \\ \hline
\multirow{1}{*}{Tri*} &  ~\cite{Chuang}    & $2m+n+o(n)$  & $O(1)$      & $O(deg(x))$    & $O(1)$   \\ \hline
                           
\multirow{2}{*}{Sep*} &  ~\cite{compact-representation}    & $O(n$)  & $O(1)$      & $O(deg(x))$    & $O(1)$   \\ \cline{2-6} 
                           &  ~\cite{succinct-representation}    &  $o(n)+H$     & $O(1)$      & $O(deg(x))$    & $O(1)$   \\ \hline
\end{tabular}
\end{table}






\bigskip

Blandford $et$ $al.$~\cite{compact-representation} made use of the unlabelled graphs with small separators to compactly represent the graph, whose representation used $O(n)$ bits on graph satisfies a $n^{c}$-separator theorem, while supported degree and adjacency queries in $O(1)$ time, and neighbourhood queries in constant time per neighbour. Subsequently, Blelloch $et$ $al.$~\cite{succinct-representation} proposed a succinct representation of unlabelled separable graphs, which used $lg| \chi |+ o(n)$ bits to represent a graph in type $\chi$, while holding the same time bounds as the performance of Blandford's representation. A summary of the performance of various of succinct planar graph representations is shown in Table 1.1.
        




\section{Preliminaries}

\textbf{Graph Separator}. A family of graphs $G$ is define separable if: it is closed under taking subgraphs, and satisfies the $f(.)$-separator theorem ~\cite{separator-theorem} if there is a constant $\alpha$ $<$ 1 and $\beta$ $>$ 0 such that each member graph in G with n vertexes has a separator set S of size $|S|$ $<$ $\beta f(n)$, that partition the graph into two parts A and B, with at most $\alpha n$ vertexes in each. A graph is separable if it belongs to a separable family of graphs. 

\bigskip
\bigskip

In this project we focus on the graphs that satisfy the $n^{c}$-separator theorem for some constant $c < 1$. One class of graphs that reaches this specifications is the planar graphs, which satisfies the theorem that $c = \frac{1}{2}$ . Another example can be well-shaped meshes in $\mathbb{R}^{d}$ , with separators of size $O(n^{1-1/d})$~\cite{ separators-sphere-packing}. We will say a graph is separable if it is undera class of graph which satisfies the $n^{c}$-separator theorem. Lipton $et al$.~\cite{Nested-Dissection} prove that all classes of graph which satisfy $n/(\log n )^{1+\epsilon}$-separator theorem have bounded density. The bounded density means that every n-vertex member in a class if graphs have bounded $O(n)$ edges. So we can assert that the separable graphs have bounded density.

\bigskip
\bigskip

By making use of the definitions above, we define a class of graphs G satisfies a $f(n)$-edge separator theorem if there are constant variables $\alpha$ $<$ 1 and $\beta$ $>$ 0 such that each member graph in $G$ with n vertexes, has an edge separator with at most $\beta f(n)$ edges whose removal partitions the graph into two subgraphs with at most $\alpha n$ vertexes in each. The edge separator is not as common as the vertex separator, because a graph with an edge separator of size s also has a vertex separator of size s at most, but no similar bound holds when it is conversed~\cite{compact-representation}.

\bigskip
\bigskip

In this project, we only considered the connected graph, which meant all vertexes in the graph have nonzero degree, and we assumed each step of partitioning always returns a edge separator set of size $O(n^{c})$.

\bigskip
\bigskip

\textbf{Queries}. Our data structure supports three kinds of queries on separable graphs: adjacency queries, degree queries and neighbour listing. The adjacency query checks whether there is an edge between two vertices, the neighbour listing returns the neighbours of a given vertex, and the degree query reports the number of edges connected to a given vertex.

\bigskip
\bigskip

\textbf{Bit Vector}. The compact representation stores a separable graph as a difference-encoded bit sequence in memory. To support the three kinds queries (adjacency queries, degree queries and neighbour listing) in constant time, knowing both the number of encoded adjacency lists in the sequence up to an index position, and the start position of a particular adjacency is necessary. More formally, the compact representation requires data structures that support rank and select operations in constant time: Given a set $B[0...n)$ to represented a subset $S$ of a universe $U = [0...n)$ = $\{0,1,...,n-1 \}$, where $B[i] = 1 \ iff \ i \in S$,

\begin{itemize}[noitemsep]
\item $rank_{q}(x)$ = $\{k \in [0...x] : B|k| = q \}$
\item $select_{q}(x)$ = $ min \{ k \in [0...n) : rank_{q}(k) = x \} $ 
\end{itemize}

\bigskip

In this project, we used two kinds of succinct data structures on bit vector: RRR~\cite{RRR} and SD vector~\cite{SD-vector} in order to build the index structure which supports queries on a separable graph. Both structures satisfy information-theoretic lower bound, and still supports efficient rank and select query operations.

\bigskip
\bigskip

\textbf{Adjacency Tables}. An adjacency list representation for a graph associates each vertex in the graph with the collection of its neighbouring vertices. For use as a data structure, the main alternative to the adjacency list is the adjacency matrix. For a sparse graph (most pairs of vertices are not connected by edges), in our case, a graph has $bounded \ mdensity$, an adjacency list representation is significantly more space-efficient than an adjacency matrix representation: the space cost of the adjacency list representation depends on the number of edges and vertices in the graph, while the adjacency matrix representation is stored as the square of the number of vertices. Generally, an adjacency list representation for an undirected graph requires 8$|E|$ bytes (2*32*$|E|$ bits) of space, where $|E|$ is the number of edges in the graph. However, it is not space-efficient enough yet.

\bigskip
\bigskip

In our project, we assigned each vertex in the graph an integer label. For each vertex, we stored an adjacency list which contains its all neighbouring vertexes. If a vertex with label $v$ has neighbours $v_{1}, v_{2}, v_{3}, ...,v_{n}$ in ascending sorted order, then we encoded the difference between each adjacency pair in the adjacency list as $|v_{1}-v|, \ |v_{2}-v_{1}|,\  |v_{3}-v_{2}|,\ ...,\ |v_{n}-v_{n-1}|$ contiguously, which forms a sequence of bits stored in memory. We used the Elias gamma code~\cite{Gamma} to encode the differences, which uses $2\lfloor \log n \rfloor + 1$ bits to encode a difference. The difference $v_{1} - v$ may be negative in some cases, we here stored a one-bit flag that value. To implement one of our index structures, the degree of each vertex needs to be encoded at the start position of the corresponding adjacency. By concatenating all the adjacency lists in the order of the vertex labels, we formed an adjacency table. To access the adjacency list of a vertex, knowing the starting position of the adjacency
is necessary. The easiest and fastest approach is to store an array of offset pointers of size $O(\log (n))$ for each. But if doing so, we would use $nO(\log (n))$ space, which exceeds our space bound. Alternatively, we implemented other two index structures proposed by Blandfor~\cite{compact-representation}, as well as two index structures based on succinct data structure on bit vector, which use less space cost down to $O(n)$ bits.
\bigskip
\begin{lemma}
An adjacency table can support degree queries in $O(1)$ time, and neighbour
listing in $O(d)$ time, where $d$ is the degree of the vertex.
\end{lemma}
\bigskip 
\begin{proof}
To access an adjacency list of a particular vertex, we use our index structure to locate its starting position in constant time. Each adjacency list consists of an encoded degree number and a sequence of encoded differences, which use $O(\log (n))$ bits and $dO(\log (n))$ bits respectively. By taking advantages of the $O(\log n)$-bits parallelism computation, we can decode any $O(\log (n))$-bits value in constant time, like using a lookup table. Hence we can decode the degree at the starting of each adjacency list in constant time. For neighbour listing, we decode each difference pair in constant time. So it takes constant time to make degree queries, and $O(d)$ time to make neighbourhood queries, where d is the degree of the vertex.
\end{proof}

\section{Outline}
This report is organized as follows. Chapter 1 shows the motivation of this project, and provides some preliminaries used in this project. Chapter 2 and 3 explain the construction and usage of the edge separator tree and several index structures respectively. Chapter 4 describes the experimental setup and examines the performance of our data structure. Chapter 5 shows the conclusion as well as the future work of our project.

\chapter{Edge Separator Tree}


\section{Building Edge Separator Tree}

\textbf{Edge Separator}. To compactly represent a graph, the first thing we need to do is building an edge separator tree from the target tree. The tree-building process is based on recursively partitioning the tree into two parts using edge separator. One example that illustrates the function of edge separator is shown in Figure 2.1: Assuming we have an 8-vertex graph $G_{1}$ with 9 edges, by removing the two edges $(v_{1}, v_{9})$ and $(v_{1}, v_{5})$, we can partition $G_{1}$ into two parts with 4 vertexes in each. Hence the edge separator in this partitioning step is $\{(v_{1}, v_{9}),(v_{1}, v_{5}) \}$.

\bigskip

\begin{figure}[ht]
\centering
\includegraphics[width=0.7\textwidth]{partition}
\caption{An example of a partition process using edge separator}
\end{figure}

\bigskip

We can see that each time we make a partitioning on a graph, it splits its vertex set and parts of edges set, and removes some edges. if we perform this partitioning recursively until only one vertex left, then we have an edge separator tree from the graph, one edge separator tree for the $G1$ in Figure 2.1 is shown in Figure 2.2. Each vertex in a graph will appear once in a leaf of the edge separator tree build from that graph. Each internal node is the set of edges used as edge separators to make partitioning in each step.

\begin{figure}[ht]
\centering
\includegraphics[width=0.8\textwidth]{separatorTree}
\caption{An example of edge separator tree}
\end{figure}

\bigskip
\bigskip
Note that we arbitrarily decided which side of the partition will be the left child or the right child at this stage. The tree is also not perfectly balanced in some cases (e.g. one child is a leaf and the other is an internal node), the side of the children is also decided arbitrarily. We will take advantages of this "freedom" to further reduce the space to encode the graph in later time. The vertex labels may be disordered by making in-order traversal on the edge separator tree (e.g. in Figure 2.2 the order of the vertexes after in-order traversal is :$v_{1}$, $v_{4}$, $v_{2}$, $v_{3}$, $v_{5}$, $v_{6}$, $v_{7}$, $v_{8}$), we will renumber these vertex by making a in-order traversal along the edge separator tree.

\bigskip
\bigskip

\textbf{METIS Partition Library}. To recursively partition a given graph, we used METIS's API in our project. METIS is an open source library developed by Karypis lab at the University of Minnesota. It supports set of serial programs for partitioning graphs and partitioning finite element meshes. The algorithms implemented in METIS are based on the multilevel recursive-bisection, multilevel k-way, and multi-constraint partitioning schemes [2]. The METIS partitioning API returns one integer list with vertex index as the key, and a flag 0 or 1 to indicate which side of partitioning the vertex belongs to. The returned value of METIS API does not provide information about edges, and the API takes two integer arrays (adjacency list of current graph and the index of vertex in adjacency list)as input parameters, hence before each calling of the METIS API, we need to generate an adjacency list and an index list for the current graph to be partitioned, and in order to collect the edge separators, we need both the adjacency list and the returned values after calling the API.

\bigskip
\bigskip

The Algorithm to build the separator tree is given in Algorithm 1. Here we use $(V,E)$
to represent a graph for simplicity, but in fact, the METIS API takes formalized adjacency list and the index list as input parameters. So each time to call the METIS API, the current vertex set need to be renumbered temporally in contiguous ascending numbers, and the adjacency list needs to be initialized according to the temporal order. The METIS API also does not support to partition the graph with the vertex amount under 3, therefore, the very basic partitioning cases are defined by ourselves.

\bigskip

\begin{algorithm}
    \underline{buildTree} $(V,E)$\;
    \eIf{$|V|=1$}
      {
        return $V$\;
      }
      {
      	$(V_{a},V_{b})$ $\leftarrow$ \textbf{METIS$\_$API} $(V,E)$  \;
		$E_{sep}$ $\leftarrow$ \textbf{findEdgeSeparator} $(V,E,V_{a},V_{b})$ \;
		$E'$ = $E \  - \ E_{sep}$   \;
      	$E_{a}$ $\leftarrow$ $\{ (u,v) \in E' \ | \  u\in V_{a} \vee v \in V_{b} \}$ \;
		$E_{b}$ = $E'$ - $E_{a}$ \;
		$T_{a}$ $\leftarrow$ \textbf{buildTree} $(V_{a},E_{a})$ \;
		$T_{b}$ $\leftarrow$ \textbf{buildTree} $(V_{b},E_{b})$ \;  
        return \textbf{separatorTree} $(T_{a}, E_{sep}, T_{b})$ \; 
      }
    \caption{Building the edge separator tree}
\end{algorithm}
\bigskip

\textbf{Building Adjacency Table}. After getting the edge separator tree, we need to renumber the vertexes based on an in-order traversal along the tree. Each vertex appears in one leaf of the tree will receive a new label which increases by one when visiting a new leaf node. A mapping table is also generated after completing the traversal, which will be used to build an adjacency list for each renumbered vertex by using the new vertex labels. Then we can build an adjacency list for each vertex, the list contains all the neighbouring vertexes in sorted order. We use gamma code to encode the difference of each adjacency pair in the list (e.g. $v_{1} - v$, $v_{2} - v_{1}$,..., $v_{n-1} - v_{n-2}$), each difference d costs $2\lfloor \log n \rfloor + 1$ bits to be encoded. Note that the value $v -v_{1}$ might be negative, so we store one flag bit for it. We also encode the number of the entries in an adjacency list at the starting position of the list, which will be used to support degree queries in constant time.

\bigskip
\begin{lemma}
Any n-vertex member in a class of graphs which satisfies a $n^{c}-edge$ separator
theorem, can be encoded in $O(n)$ bits using an adjacency table.
\end{lemma}


\begin{proof}
For each edge $(u, v)$ in an edge separator in a graph with s vertexes, the difference
between vertex u and vertex v is $O(s)$. We use gamma code to encode the difference which would use $O(\log (s))$ bits, so that edge will contribute $O(\log (s))$ bits to the adjacency lists of both vertex u and vertex v. Hence, we charge $O(\log (s))$ to every edge in a separator of a graph with s vertices. Recall that by using the $n^{c}- edge$ separator theorem, each member with n vertexes in the class of the graph has a $\beta n^{c}$ edge separator whose removal partitions the member into two parts with at most $\beta n$ vertexes in each. Let define $S(n)$ to be an upper bound of required bits to encode a graph with n vertexes, and let $\alpha < a < 1 - \alpha $, then $S(n)$ satisfies the recurrence:
\[ S(n) \leq S(an) + S(n-an) + O(n^{c} \log n) \]
This recurrence can be solved to $S(n) = O(n)$, and the bits to encode the degree of all the vertexes is bounded by $O(n)$, because there are $O(n)$ edges in total. So the total space is $O(n)$ bits.
\end{proof}

\bigskip
\bigskip

\section{Post Processing}

\textbf{Child-flipping Algorithm}. When encoding the graph, We contiguously encode the difference between each adjacency pair in the list by using gamma code. The gamma code use $2\lfloor \log d \rfloor + 1$ bits to encode a difference $d$. If we can make each difference "smaller", in other words, if we can make the labels of vertexes in an adjacency list closer to each other, then we can reduce the space to encode the adjacency list. We arbitrarily decide the side of partitioning during the construction of the separator tree (in our project, we decided the side of partitioning according to the output value of METIS API: '0' to the left child and '1' to right child), so there is a degree of freedom in the way to build the tree. To take advantage of this freedom, we can apply a heuristic optimization method called "child-flipping"~\cite{compact-representation} to our edge separator tree.

\bigskip
\bigskip

The child-flipping algorithm works when making traversal along a separator tree, it tracks the nodes containing vertex labels which appear before and after the vertex labels in the current node. Let define $N_{L}$ to be the left children of current node's left ancestors and $N_{R}$ to be the right children of the current node's right ancestors, $N_{1}$ and $N_{2}$ represents the current node's left child and right child, respectively, and $E_{AB}$ indicates the number of edges between the vertexes in node A and node B. For each node, the vertexes in $N_{1}$ of the current node will have labels less than the vertexes' under the node, the vertexes in $N_{2}$ will have larger labels than all the vertexes under the node, and there is no intersection between the vertexes in $N_{L}$ and $N_{R}$ of the node. The child-flipping exams $E_{N_{L}N_{1}}$, $E_{N_{2}N_{R}}$, $E_{N_{L}N_{2}}$ and $E_{N_{1}N_{R}}$ of each node to ensure that $E_{N_{L}N_{1}} + E_{N_{L}N_{1}} \leq E_{N_{L}N_{1}} + E_{N_{L}N_{1}}$. If not, the child-flipping algorithm swaps the two children of current node. The meaning of making this swap is : after renumbering the vertexes based on an in-order traversal, if $E_{N_{L}N_{1}} + E_{N_{L}N_{1}} < E_{N_{L}N_{1}} + E_{N_{L}N_{1}}$, then the space to encode the edges $N_{L}N_{2}$ and $N_{1}N_{R}$ is greater than that to encode $N_{L}N_{2}$ and $N_{1}N_{R}$, because the difference $v_{N_{2}} -v_{N_{L}}$ is obviously greater than $v_{N_{1}} - v_{N_{L}}$, similar fact works on the difference of $v_{N_{R}}-v_{N_{1}} \  and \  v_{N_{R}}-v_{N_{2}}$.

\bigskip
\bigskip

\textbf{Speed Up the Child-flipping Algorithm}. This heuristic algorithm can be applied to any edge separator tree as a postprocessing step. However, this process is quite time-consuming, the time cost of applying both METIS and child-flipping in Blandfor $et al.$ ~\cite{compact-representation}'s experiment shows a demonstration on this. To get the four numbers of edges($E_{N_{L}N_{1}}$, $E_{N_{2}N_{R}}$, $E_{N_{L}N_{2}}$ and $E_{N_{1}N_{R}}$ ), we need to have the four vertex sets: $N_{L}$, $N_{R}$, $N_{1}$ and $N_{2}$ for each tree node. The $N_{L}$ and $N_{R}$ of each node in separator tree can be pre-collected, but the $N_{1}$ and $N_{2}$ need to be calculate locally when reach the node. In our project, we make some efforts to reduce the time to conduct this child-flipping processing: Let assume we have a node $N_{a}$ in a separator tree with left child as $N_{b}$ and right child as $N_{c}$, if we knew the $N_{1}$ and $N_{2}$ of Na (denote as $N_{1a}$ and $N_{2a}$), then

\begin{itemize}[noitemsep]
\item for node b : $ N_{1b} = N_{1a}, N_{2b} = N_{2a} \cup N_{Ra}$
\item for node c : $ N_{1c} = N_{1a} \cup N_{La}, N_{2c} = N_{2a}$ 
\end{itemize}

Having this general case, then we can generate the $N_{1}$ and $N_{2}$ for each node during the child-flipping traversal via DFS. The $N_{L}$ and $N_{R}$ of each node in separator tree can be pre-collected via a post-order traversal along the edge separator tree, the vertex set of a tree node is formed by merging the two vertex sets of its children in sorted order. When needing to expand the current $N_{1}$ or $N_{1}$, we include the new coming $N_{L}$ or $N_{R}$ as distinct sorted set instead of merging $N_{L}$ into $N_{1}$ or $N_{R}$ into $N_{2}$. Note that in term of a node, the size of $N_{L}$ or $N_{R}$ is always smaller that the size of $N_{1}$ or $N_{2}$, respectively. We check an existing of an edge by performing binary on larger sorted set, all of above approaches improve the speed of child-flipping processing significantly.

\chapter{Index Structure}

We have already introduced how to encode a graph with good edge separator into difference adjacency table bounded by $O(n)$ bits, but to access to the particular adjacency list for a particular vertex, we need to know the exact starting position in the bit sequence. Hence our representation requires a data structure that supports efficient select operations on the bit sequence. Note that, the space cost of the data structure should not exceed our space bound which is $O(n)$. Blandfor $et al.$ had proposed three kinds of index structure: $direct$, $semi-direct$, and $indirect$~\cite{compact-representation} to support efficient select queries. In addition to these three structures, we also implement other two index structures based on RRR and SD Vector, respectively, we will henceforth call these two RRR-based and SDV-based index structure. We will introduce all the five indexing structures in this chapter.

\bigskip
\bigskip

\textbf{Direct indexing structure}. The easiest way to access to the starting position of 
any adjacency list is to store an offset pointer for each vertex. Because our representation uses $O(n)$ bits to store a separable graph, one offset pointer will use $\Theta (\log (n))$ bits. For all vertexes, it will use $n \Theta (\log (n))$ in total. If we want to locate the starting position of any vertex, only one memory access is needed, so this approach is fastest among the five index structures. In our implementation, we allocate one word (32 bits) space for each vertex, hence the total space for this direct index structure is 4$n$ bytes.

\bigskip
\bigskip

\textbf{Semi-direct indexing structure}. This $semi-direct$ index structure is very similar to the $direct$ structure, but instead of allocating one-word space for each vertex, we use two words to store four offset values. Let say we have four vertexes $v_{n}$, $v_{n+1}$, $v_{n+2}$, $v_{n+3}$, The first word space will store the pointer value of $v_{n}$, then use the second word to store three offset value $v_{n+1}$-$v_{n}$, $v_{n+2}$-$v_{n}$, $v_{n+3}$-$v_{n}$. If the space of the three offset values exceeds one-word bound, then store the offsets somewhere else, then the second word store a pointer pointed to them. Compared to the $direct$ structure, if the vertex satisfies $v_{id}$ mod 4 = 0, then it works exactly as same as $direct$ structure, if not, it firstly gets the real offset by adding the corresponding offset to the first pointer value, then access the memory directly. If every four vertexes fit into two-word space, then this $semi-direct$ structure would use half of the space used by the $direct$ structure.     

\bigskip
\bigskip

\textbf{Indirect indexing structure}. Note that the above two index structure use $n \theta (n)$, which exceeds $O(n)$ space bound. To limit the space cost within the bound, Blandfor $et al.$ implement the third structure: $indirct$, which use $O(n)$ space meanwhile supports constant time on locating vertex. The component of the structure is shown in  Figure 3.1: we first divide all vertexes into blocks with $\log(n)$ vertexes in each, then we further divide each block into subblocks. Each subblock contains a minimal number of vertexes whose indexing offset length reaches at least $k\log(n)$ bits for some constant number $k$. We store a bit vector with $\log(n)$ bits length for each block, if $v_{i}$ is the first vertex in its subblock, then the ($i$ mod $\log (n)$)$_{th}$ bit in the vector of its block is set to 1, otherwise 0. We only store the offset pointers of vertexes if their corresponding bits in bit vector are 1. This will require $O(n)$ bits in total. 

\bigskip

\begin{figure}[ht]
\centering
\includegraphics[width=1.0\textwidth]{indirect}
\caption{The architecture of the $indirect$ indexing structure}
\end{figure}

\bigskip

To locate the starting position of a particular vertex, we first find which block the vertex is in by dividing the vertex label with $\log(n)$ (number of vertexes in each block). Next, we check the bit vector of that block to find which subblock contains the vertex. Since we store the offset pointer for the vertexes which are the first one in their subblock, we can know the starting position of the target subblock, then we decode the subblock. Although we will get all the adjacency lists within the subblock if do so, the degree information of each vertex is also encoded, hence we can have the adjacency list of the target vertex easily. The bit vector of each block has $\log(n)$ bits, each subblock is $k\log(n)$ bits long, determining and decoding the subblock can be completed by using a lookup table, which uses a constant time to check $\Theta(\log(n))$ bits.              

\bigskip
\bigskip

\textbf{RRR-based indexing structure}. RRR is a succinct data structure which was first proposed by Raman $et al$.~\cite{RRR}. This data structure works on bit sequence $S[0,...,n)$ in such a way that provides rank and select operations in $O(1)$ time at the price of $nH_{0}(S)+o(n)$ space cost, where $H_{0}(S)$ is the empirical zero-order entropy of the sequence. The RRR data structure divides the original bit sequence into several superblocks, then divide the superblocks further. For each block, it stores a number to indicate the number of ones or zeros in the block. The number would be used as a lookup key in a table. Besides that, it also stores an offset which indicates which of the blocks the number is in. The offset is also used as an index in the table. By grouping blocks into superblock, RRR can avoid iterating over each block to conduct a rank or select query. 

\bigskip
\bigskip

RRR efficiently compresses a bit set if the set is very sparse populated, we take advantage of this feature of RRR and implement an indexing structure based on it. The original graph is encoded into a bit sequence by using gamma code, and we know the length of this sequence. Hence we can maintain another bit set with the same length as the encoded bit sequence, in which we set a bit to '1' if it is the starting point of an adjacency list, otherwise we set the bit to 0. By doing so, we get a bit set which is very '1' sparse, then we can build RRR bit vector on this bit set. To locate a particular vertex, we only need to conduct a $select$ query on the RRR bit vector, and we will know its starting position in the encoded bit sequence in constant time. Since the encoded bit sequence is $O(n)$ bits long, and for a n-bit sequence, RRR needs $nH_{0}(S)+o(n)$ bits to support constant $rank$ and $select$ queries. We do not need to store additional information besides RRR structure, so the space cost will not exceed our bound. 

\bigskip
\bigskip

\textbf{SD Vector-based indexing structure}. SD Vector is a bit vector that can compress very sparse populated bit vectors by representing the positions of 1 by the Elias~\cite{Elias} - Fano~\cite{Fano} representation for non-decreasing sequences. Given a bit set $B[0,...n-1)$ with $m$ ones ($m << n$),   the SD Vector uses $m \log n/m  + 2m + o(m)$~\cite{Practical-Entropy} bits to store the bit set, meanwhile support constant time $rank$ and $select$ queries. The idea of SD Vector-based indexing structure is very similar to RRR-based indexing structure. We firstly maintain a bit sequence which has the same length as the encoded graph bit sequence, next we mark the bits which indicate the starting position of an adjacency list, then we build an SD Vector on this bit sequence. In order to locate the starting position of a particular vertex, we use the SD Vector to perform a $select$ operation which would return the expected position. 


\chapter{Experiment}
After implementing our data structure by encoding a graph into an adjacency table as well as building an auxiliary indexing structure for supporting queries on the graph, we'd like to exam the performance of our approach. In this chapter we will first describe the experimental setup which includes some our implementation detail in terms of succinct representation of bit vector, as well as our decoding approach. Then show and discuss our experiment result.

\bigskip
 
\section{Experiment Setup}

\bigskip
\textbf{RRR and SD Vector}. As we introduced in Chapter 3, we take advantage of the features of succinct representation of bit vector to build two indexing structures: RRR-based and SD Vector-based. We implemented both RRR and SD Vector structures by using the succinct data structure API provided by Simon Gog~\cite{sdsl}, which presents a various of succinct representations including bit vector, Integer Vectors, Wavelet Trees, Compressed Suffix Arrays (CSA), etc. The API for RRR and SD Vector works when a bit set is provided, then it builds $select\_support\_type$ or $rank\_support\_type$ data structure on it. A $select$ or $rank$ operation then can be called by using member functions within the $select\_support\_type$ or $rank\_support\_type$ objects.  

\bigskip
\bigskip

\textbf{Decoding}. Taking advantage of the feature of Random-Access-Machine that costs constant-time to perform operations on $O(\lg n)$ bits, we can decode any $O(\lg n)$-bit words in constant time. One practical approach here is using a lookup table. In our project, the graph is Elias gamma encoded, to ensure a decoding operation on $O(\lg n)$-bits requires constant time, we implement a table to decode multiple gamma codes at once. For a fixed number of $k_{g}$, we create a table of size $2^{k_{g}}$, and use the numbers range from 0~$2^{k_{g}}$ as indexes. Each entry in the table indicates a decoding result which is represented by a 32-bit word.  

\bigskip

\begin{figure}[ht]
\centering
\includegraphics[width=1.0\textwidth]{Decoding}
\caption{The working mechanism of the lookup table}
\end{figure}

\bigskip

The working mechanism of this lookup table is shown in Figure 4.1 (note that we set the $k_{g}$ to 16, and limit the number of words decoded at once to 3 in our implementation): the first two bits indicate the number of values that this 16 bits decode to. If a bit block with size of 16 can not be directly decoded (e.g. the first case in the Figure 4.1, which is all zero), then the firstly two bits in the corresponding entry is set to 0, which means none of number can be decoded in this block. The next 24 bits ($3_{rd} - 26_{th}$ bits) indicate the three potential decoding result (if the first two bits show that only one number can be decoded, then we only look into the $3_{rd} - 11_{rd}$ bits). The next 5 bits ($27_{th} - 31_{th}$ bits) show the number of unused bits which will be used in next lookup operation, and the last bit is unused. This makes each table entry fit into 32 bits. If the first two bits indicate that none value can be directed decoded by checking this table entry, then the sequence will be decoded explicitly (counting zeros then get the value).

\textbf{Test Graphs}. The test graph used in our experiment come from several source: two 3D Mesh graphs from an online Graph Partitioning Archive maintained by C. Walshaw~\cite{3DMESH}, one graph from Scotch Graph Archive maintained by Dave Beckett~\cite{Scotch}, one graph from RIACS Graph Archive~\cite{RIACS}, two Gpu Layout Plugin graphs from Cytoscape online resource~\cite{Cytoscape}, and two BCS Structural Engineering Matrix graphs from Matrix Market~\cite{Matrix}. All the test graphs are undirected graphs, a summary of general attributes of the graphs is shown in Table 4.1, giving the information about the numbers of vertexes and edges, max degree and graph source.


\begin{table}[ht]
\centering
\caption{ Test graphs used in our experiment }
\label{graph-list}
\begin{tabular}{|l||c|c|c|c|}
\hline
\multicolumn{1}{|c||}{Graph} & Vertexes & Edges   & Max Degree & Source        \\ \hline
feocean                   & 143437   & 409593  & 6          & 3D mesh~\cite{3DMESH}        \\
m14b                      & 214765   & 1679018 & 40         & 3D mesh~\cite{3DMESH}       \\
febody                    & 45087    & 163734  & 28         & Scotch Graphs~\cite{Scotch} \\ 
wave                      & 156317   & 1059331 & 44         & RIACS Grids~\cite{RIACS}    \\
598a                      & 110971   & 741934  & 26         & Cytoscape~\cite{Cytoscape}      \\
144                       & 144649   & 1074393 & 26         & Cytoscape~\cite{Cytoscape}     \\
bcsstk30                  & 28924    & 1007284 & 218        & BCS~\cite{Matrix}    \\
bcsstk31                  & 35588    & 572914  & 188        & BCS~\cite{Matrix}     \\ \hline
\end{tabular}
\end{table}


\section{Experiment Result}. The experiments were conducted on a Linux server containing 32 Intel Xeon E5-2650 @ 2.00GHz cores and 256 Gigabytes main memory.
We present each edge in undirected graphs in both directions, which means the space cost measured by bits per edge is reported for each direction. Our experiment focus on three parameters of concern: the time to construct our data structure, the time to perform queries on graph and the space needed to encode the graph into adjacency table. The space cost of our data structure consists of the space for adjacency table, and the space for the indexing structure. There are a trade-off between the time to complete the construction and the space for encoding the adjacency table caused by whether conduct the child-flipping process, as well as a trade-off between the space for the indexing data structure and the time to perform queries on graphs resulted by applying different indexing structures. Our experiments present demonstration on these trade-offs.

\bigskip
\bigskip


Table 4.2 shows the time cost of constructing the compact data structure and the space needed to encoding the adjacency table. We can see that the child-flipping causes additional time cost as a heuristic postprocessing phase, but do reduce the space cost of the adjacency table (save at most 8\% space on the febody graph, and at least 2.5\% space on the bcsstk30 graph). The degree space for each graph is listed separately, because the child-flipping process will not change the degree of each vertex, and the number of bits to encode a number is fixed (use $2\lfloor \log d \rfloor + 1$ bits to encode a degree $d$ by using Elias gamma coding).   

\begin{table}[]
\centering
\caption{The performance of compact mechanisms. Time is in seconds and space is in bits per edge for encoding the edges}
\label{compact-performance}
\begin{tabular}{|l||c|c||c|c||c|}
\cline{2-6}
\hline
\multirow{2}{*}{Graph} & \multicolumn{2}{c||}{METIS} & \multicolumn{2}{c||}{METIS-CF} & \multirow{2}{*}{Degree} \\ \cline{2-5}
                       & Time          & Space        & Time           & Space         &                         \\ \cline{6-6} \hline
feocean                & 55.69         & 8.68         & 59.51          & 8.27          & 0.86                    \\
m14b                   & 129.3         & 5.21         & 155.37         & 5.00          & 0.51                    \\
febody                 & 6.33          & 4.64         & 7.2            & 4.25          & 0.82                    \\
wave                   & 77.4          & 5.76         & 86.52          & 5.57          & 0.55                    \\
598a                   & 39.06         & 5.45         & 52.33          & 5.21          & 0.54                    \\
144                    & 67.09         & 5.32         & 84.33          & 5.13          & 0.52                    \\
bcsstk30               & 7.89          & 2.29         & 12.3           & 2.24          & 0.17                    \\
bcsstk31               & 6.61          & 2.98         & 9.02           & 2.89          & 0.30                    \\ \hline
\end{tabular}
\end{table}

\bigskip
The indexing structures are built based on the ordering result after the child-flipping process. Table 4.3 illustrates the space cost of each indexing structure, while Table 4.4 illustrates the time cost to perform a breadth-first-search(BFS) on the graph by applying those indexing structures on the encoded adjacency table. The reason why we use BFS to measure the performance is because it requires visiting all the edges, which makes it a reasonable measure for our data structure. The BFS algorithm starts at some arbitrary vertex as the root (we use the $1_{st}$ vertex after renumbering in our project) and explores the neighbour nodes first, before moving to the next level neighbours, with a cost of time $\Theta(|V| + |E|)$. 

\bigskip
\bigskip

We also compare the performance of our representation to that of an array-based adjacency list graph representation. The array-based adjacency list representation store all the neighbours of each vertex contiguously in a large array with the neighbour lists place one after the other. It also require an array to store the index of each vertex. Therefore, it use one 32-bit word to present an edge and one 32-bit word as the index of one vertex, taking 8$|E|$ bytes (2*32*$|E|$ bits) space for list and 4$|V|$ bytes for indexes in total. For the BFS algorithm on any types of indexing structures, we use one bit flag to indicate whether a vertex has been visited.
\bigskip     

\begin{table}[ht]
\centering
\caption{The space cost of different indexing structures. Space is in bits per edge.}
\label{my-label}
\begin{tabular}{|l||c||c||c||c||c|}
\hline
Graph    & Direct & Semi & Indirect & RRR & SD Vector \\ \hline
feocean  &    5.63    &   2.81   &     0.84     &  2.03   &   1.59        \\
m14b     &    2.05    &   1.02   &    0.42      &  1.01   &   0.64        \\
febody   &    4.46   &   2.23   &     0.54     &  1.33   &    1.31        \\
wave     &   2.36    &   1.18   &    0.46      &   1.14   &   0.72         \\
598a     &    2.39    &   1.19   &   0.47       &  1.10   &    0.77       \\
144      &    2.15   &   1.07   &    0.43      &  1.05    &   0.67          \\
bcsstk30 &   0.46   &   0.23   &      0.12    &   0.35   &   0.16        \\
bcsstk31 &   0.93   &   0.46   &     0.21     &  0.54   &   0.35        \\ \hline
%Avg      &    2.54   &   1.27   &     0.46     &  1.06   &    0.77       \\
%\hline
\end{tabular}
\end{table}

\bigskip

The experimental result shows that the $direct$ and $semi direct$ indexing structures give the fastest query time, but still slower than the array-based adjacency list representation. It's not surprising because the array-based representation has good spacial locality, which means the edges of a vertex are adjacent in memory and be loaded into cache as an array. In addition to that, the array-based representation does not need to decode the list, hence the array-based representation is faster than others.The $semi-direct$ indexing structure uses half of the space when compared to $direct$ indexing structure while requiring little extra time on query. $Indirect$ indexing structure shows good space usage but it is not very efficient in query, because it needs to decode a "subblock" rather than an adjacency list. The SD Vector-based structure outperforms the RRR-based structure in both space usage and time cost in all the test graphs, but since we are using the API provided by a third-party to construct RRR and SD Vector on bit set, we can not simply say the RRR structure show worse performance than SD Vector when applied on our indexing structures.     

\bigskip

\begin{table}[ht]
\centering
\caption{The time performances of different indexing structures to conduct a BFS, the time cost is measured by millisecond}
\label{my-label}
\begin{tabular}{|l||c||c||c||c||c||c|}
\hline
Graph    & Array & Direct & Semi & Indirect & RRR & SD Vector \\ \hline
feocean  &   13.6    &   31.6     &   34.9   &    97.2      &  103.3   & 60.8          \\
m14b     &   36.2    &    88.5    &   93.1   &   216.8   &  251.6   &   130.7        \\
febody   &   2.5    &    7.3    &   7.9   &     27.7    &   33.7  &     13.8      \\
wave     &    19.9   &    60.8    &   66.1   &    144.8     &   176.2  &   95.1        \\
598a     &    14.5   &    42.1    &   45.9   &    102.8     &  115.0   &    65.6       \\
144      &   19.2    &    60.0    &   64.7   &     111.2     &  130.4   &  87.9         \\
bcsstk30 &   4.2    &    24.9    &   26.8   &    37.0    &   40.9  &  29.3         \\
bcsstk31 &    3.7   &    20.2    &   20.7   &     35.4    &   39.2  &  27.9         \\ \hline
%Avg      &    14.2   &    41.9    &  45.0  &          &     &           \\
%\hline
\end{tabular}
\end{table}

\bigskip

Table 4.5 illustrates a summary of performance of different indexing structures associated with the encoded adjacency table built after child-flipping process. The space for each mechanism contains the space for the encoded adjacency list, the space for degree and the space for the indexing structure. We can see that the $direct$ indexing structure gives fastest query speed while requiring the most space, $indirect$ indexing structure use least space while needing more time on query, the SD Vecter-based indexing structure presents a good trade-off between the space usage and query efficiency. 


\begin{table}[ht]
\centering
\caption{Summary of space and time performance. Space is in bits per edge and time is in millisecond}
\label{my-label}
\begin{tabular}{|l||c|c||c|c||c|c||c|c||c|c||c|c|}
\hline
\multirow{2}{*}{Graph} & \multicolumn{2}{c||}{Array} & \multicolumn{2}{c||}{Metis/Di} & \multicolumn{2}{c||}{Metis/SemD} & \multicolumn{2}{c||}{Metis/Ind} & \multicolumn{2}{c||}{Metis/RRR} & \multicolumn{2}{c|}{Metis/SD\_V} \\ \cline{2-13}
                       & \textit{T}        & \textit{S}       & \textit{T}           & \textit{S}           & \textit{T} & \textit{S}          & \textit{T}            & \textit{S}           & \textit{T}          & \textit{S}        & \textit{T} & \textit{S} \\ \hline
feo*          & 13.6  & 37.6   &  31.6  &  14.8  &  34.9   &   11.94  &  97.2  &  9.8  &  103.3  &  11.06  &  60.8  &  10.6              \\
m14b          & 36.2  & 34.1   &  88.5  &  7.6  &  93.1   &  6.53   &  216.8  &  5.9  &  251.6  &  6.52  &  130.7  &   6.1             \\
feb*          & 2.5   & 36.4   &  7.3   &  9.5  &  7.9   &  7.3   &  27.7  &  5.6  &  33.7  &  6.4  &  13.8  &  6.4              \\
wave          & 19.9  & 34.3   &  60.8  &  8.5  &  66.1   &  7.3   &  144.8  &  6.5  &  176.2  &  7.2  &  95.1  &  6.8              \\
598a          & 14.5  & 34.4   &  42.1  &  8.1   &  45.9   &  6.9   &  102.8  &  6.2  &  115.0  &  6.8  &  65.6  &  6.5              \\
144           & 19.2  & 34.1   & 60.0   &  7.8  &   64.7  &  6.7   &  111.2  &  6.1  &  130.4   &  6.7  &  87.9  &  6.3              \\
b30*          & 4.2   & 32.4   &  24.9  &  2.8  &  26.8   &  2.6   &  37.0  &  2.5  &  40.9  &  2.7  &  29.3  &   2.5             \\ 
b31*          & 3.7   &  33.0  &  20.7  &  4.2  &   20.7  &   3.6  &  35.4  &  3.4  &  39.2  &  3.7  &  27.9  &   3.5             \\ \hline


\end{tabular}
\end{table}

\chapter{Conclusion and Future Work}

In this project, we focus on how to represent a separable graph compactly while supporting efficient query. Our theoretical basis comes from a previous work conducted by Blandfor $et \ al.$~\cite{compact-representation}, which provides the theory of using vertex separator to compactly represent the graph. The representation takes $O(n)$ bits, meanwhile using constant time on degree or adjacency query, and neighbour listing for one vertex in constant time per neighbour. 

\bigskip
\bigskip

We first make a survey on the researches related to succinct data structure on planar graph, as well as some succinct representation on bit vector like RRR. Then focus on the representation of separable graph. 

\bigskip
\bigskip

Next, we use the METIS$\_$API to partition the graph by removing some amount of edges recursively, and construct the edge separator tree for the graph. To reduce the space of difference encoding, we conduct a heuristic postprocessing phase called "child-flipping" on the edge separator tree. We use Elias gamma code to encode the adjacency list of each vertex, and concatenate all the adjacency lists to an adjacency table.

\bigskip
\bigskip

Then we implement several indexing structures to support adjacency queries, degree queries and neighbourhood queries in constant time. Besides the three indexing structure mentioned in Blanddfor's work, we implement other two structure based on succinct representation on bit vector.

\bigskip
\bigskip

Finally we conduct some experience to measure the performance of our representation. The experiments demonstrates the trade-off between the space cost to encode the adjacency table and the time to construct the data structure, as well as the trade-off between the space cost and time of queries by different indexing structures. Compared to the array-based adjacency list representation, our approach reduces space usage by almost an order of magnitude, while supporting Breadth-first-search in acceptable running time.

\bigskip
\bigskip

For the future work, we intend to implement the separator tree by using the vertex separator, and apply different coding schemes like delta~\cite{Elias}, Huffman coding, etc. Besides that, we can try to design and implement more indexing structures to investigate more about the time/space trade-off.
 
\bibliographystyle{plain}
\bibliography{bib}

\end{document}
